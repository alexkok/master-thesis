% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% Chapter: Conclusion
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\chapter{Conclusion}
\label{cpt:conclusion}
% Summary
In this thesis, we have shown a way how the generator can be tested by using property-based testing. This is done by generating tests based on the \textit{Rebel} specification and making use of the generator to generate the tests. The \textit{Rebel} specification is build up based on a set of defined properties of \textit{Rebel}. These property definitions were not defined earlier, thus we defined many expected properties in \textit{Rebel}.\\
\\
With test framework we have found some bugs in the generated system that were unknown before. This proves that this approach already worked to identify some problems in the generator that were not known before. Additionally, we contributed to an open-source library called \textit{Squants}, by issuing two reports of bugs that existed in the library.\\
\\
% Research questions
% Answer main research question
To answer the main research question, we defined and answered the three sub research questions, which have been discussed in \autoref{cpt:discussion}. The main research question was as follows:
\begin{quote}
\rqMain
\end{quote}
A \textit{Rebel} specification is created from the defined properties. Next, the existing generator is being used to generate the generated system and to translate the properties (in the \textit{Rebel} specification) to test cases. When running the test framework, we found some errors by using the generated system. Additionally, we were able to detect a compilation error and incorrectly translated formulas.\\
\\
We conclude that, by using this approach, the semantics of the generated code can be checked automatically on whether it satisfies the defined properties. With this approach, we have found bugs in the generated code that were unknown before.

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% Section: Future work
\section{Future work}
% Multi VM testing, specify sync properties, can test with multi JVM testing etc. Sources > future work

\subsubsection{Complete property definitions}
\pinfo{Full definitions for Rebel}
In this thesis, we defined some properties on the \textit{Rebel} language,
which we consider to hold when using \textit{Rebel}. This list of property
definitions on \textit{Rebel} is not complete, there can be many more properties
and there are other types available in \textit{Rebel} which we did not cover.
Defining these and adding them to the set of property definitions is left as
future work.

\subsubsection{Values generation by using solvers}
\pinfo{Current value generation limitations}
The current value generation works for the properties that we defined throughout this thesis. When additional properties are being added, the value generator might or might not have to be updated. This depends on what preconditions have to be parsed for that property and whether the current implementation supports these operations.\\% As described, the current implementation has some limitations. It does not support expressions that are using different operators or that use expressions on both the left-hand and right-hand side (expressions here means non-literals or variables, but a combination of operators and literals/variables).\\
\\
\pinfo{Other tools possible}
Another way how the value generator could work is to use some tools to determine the random values. As we have discussed in \autoref{cpt:experiment3}, the SMT solver would theoratically be an option. But in our attempts this resulted in having the same input values every time the test framework is run. To counter this problem, other solvers might be more useful to implement this behaviour, such as \textit{SageMath}~\cite{siteSageMath2017}. \textit{SageMath} can parse expressions and determine the conditions to which each variable in the expression should hold. When using this, it would mean that the value generator has to be modified such that it integrates with this tool. Another approach could be used for this too, such as concolic testing~\cite{sen2006cute} to determine the input values. % Maybe there are some QuickCheck ports that do this already for some languages?

\subsubsection{Multiple generators}
\pinfo{Only one, support for more could be added}
Throughout this thesis, we have only tested the Scala/Akka generator which is
developed by \textit{ING}. Since there are more generators available, the test
framework can be improved such that it is
compatible with the other systems that can be generated by using one of the
other generators that are available within \textit{ING}. By doing this, the same
property definitions can be tested on different kind of generated systems. This
can be used to detect inequalities among the generated system.

\subsubsection{Mutation testing}
Another metric to evaluate the effectiveness of the test framework would be to use
mutation testing. The mutation coverage could be used to measure how
effective the test framework would be (the number of mutants created and the
number of killed mutants). Unfortunately, there is currently a limited support
for mutation testing for \textit{Scala} systems. \textit{PIT} for example, cannot meaningfully
mutate \textit{Scala} code~\cite{siteSbtPit2017}. Because of this, we did not
use this as metric to evaluate the test framework.\\
\\
\textit{Scala} compiles to \textit{Java} bytecode, mutating on bytecode level
could be used too. However, some mutants might not be relevant in that the
modifications would not affect the implementation, which can lead to
false-positives.

\subsubsection{Other components}
Besides completing the set of property definitions, the test framework could also be extended such that it
can also support property definitions concerning other components of the system. Such as the sync block
definitions, which defines actions that should happen synchronously. Or performance
measures when interacting with data in the system. Currently, such components
are not being tested and are unsupported, while these
components are also important for the bank. This is left as future work.\\
\\
It might not be possible to check each and every component
by using this approach. For example, it might be unable to check how
multiple generated systems would integrate with each other and if this is done
correctly. The generated system is configured to work with multiple
distributions of the system, but is not being tested thoroughly yet.

% Ultimately, as last
%\subsubsection{Properties based on type checker}
%\pinfo{Generating properties based on type checker}
%\textit{Rebel} contains a type checker, which is able to determine exactly
%which operations are supported by using certain combinations of operators and
%types. This could be used to automatically generate the property specifications
%in \textit{Rebel} based on whether a type supports certain operations that are
%required for the property. For example, if \textit{Percentage} supports
%addition, the properties for \textit{additivity}, \textit{associativeAddition}
%and \textit{commutativeAddition} can be generated based on this rule.\\
%\\
%A map of all operations and all existing types could be created. Next, each
%combination can be tested against the type checker. If the type checker an
%expression as correct, the event definition for some properties could be
%be generated. Although this might result in many event definitions,
%with a possible overlap between them, it could be a way to automatically
%generate the specification containing the definitions. This assumes that the type
%checker does the right thing, which is a threat to this approach. This
%can also lead to more compilation errors in the generated system. Nevertheless,
%it can make it more dynamic when a new type is being added to the \textit{Rebel}
%language.
